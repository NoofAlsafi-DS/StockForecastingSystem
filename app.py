# app.py
# Advanced Stock Price Forecaster (Realtime Yahoo Finance + Normality & ADF + Diff)

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import yfinance as yf

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

from scipy.stats import shapiro
from statsmodels.tsa.stattools import adfuller

# ============================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
# ============================
st.set_page_config(
    page_title="Advanced Stock Price Forecaster",
    layout="wide"
)

# ============================
# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
# ============================

def load_stock_data(ticker: str, years: int):
    """
    ÙŠØ¬Ù„Ø¨ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ + Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Yahoo Finance.
    """
    stock = yf.Ticker(ticker)

    # Ø³Ø¹Ø± Ù„Ø­Ø¸ÙŠ
    info = getattr(stock, "fast_info", {}) or {}
    current_price = info.get("last_price", None)

    # Ø§Ø­ØªÙŠØ§Ø· Ù„Ùˆ fast_info Ù…Ø§ Ø£Ø¹Ø·Ù‰ Ø³Ø¹Ø±
    if current_price is None:
        hist = stock.history(period="1d")
        if not hist.empty:
            current_price = float(hist["Close"].iloc[-1])
        else:
            current_price = np.nan

    # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø³Ù†ÙˆØ§Øª
    df = stock.history(period=f"{years}y")
    df = df.dropna()

    return current_price, df


def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ù…Ø¤Ø´Ø±Ø§Øª ÙÙ†ÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ©: SMA, EMA, RSI, MACD.
    """
    df = df.copy()

    df["SMA_20"] = df["Close"].rolling(20).mean()
    df["SMA_50"] = df["Close"].rolling(50).mean()
    df["EMA_10"] = df["Close"].ewm(span=10, adjust=False).mean()
    df["EMA_20"] = df["Close"].ewm(span=20, adjust=False).mean()

    # RSI
    delta = df["Close"].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(14).mean()
    avg_loss = loss.rolling(14).mean()
    rs = avg_gain / avg_loss
    df["RSI"] = 100 - (100 / (1 + rs))

    # MACD
    ema12 = df["Close"].ewm(span=12, adjust=False).mean()
    ema26 = df["Close"].ewm(span=26, adjust=False).mean()
    df["MACD"] = ema12 - ema26
    df["Signal"] = df["MACD"].ewm(span=9, adjust=False).mean()

    return df


def add_lag_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ø¥Ø¶Ø§ÙØ© Lags + Returns + Volatility.
    """
    df = df.copy()

    # Lags Ù„Ù„Ø£Ø³Ø¹Ø§Ø±
    for lag in [1, 2, 3, 5, 7, 10, 14]:
        df[f"Close_lag_{lag}"] = df["Close"].shift(lag)

    # Returns
    df["Return_1"] = df["Close"].pct_change(1)
    df["Return_3"] = df["Close"].pct_change(3)
    df["Return_7"] = df["Close"].pct_change(7)

    # Volatility
    df["Volatility_7"] = df["Return_1"].rolling(7).std()
    df["Volatility_14"] = df["Return_1"].rolling(14).std()

    return df


def check_normality(series: pd.Series):
    """
    Ø§Ø®ØªØ¨Ø§Ø± Shapiro-Wilk Ù„Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ.
    H0: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ.
    """
    s = series.dropna()
    # Shapiro Ù„Ø§ ÙŠØ­Ø¨ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø¶Ø®Ù…Ø© Ø¬Ø¯Ø§Ù‹
    if len(s) > 5000:
        s = s.sample(5000, random_state=42)

    stat, p = shapiro(s)
    return {
        "statistic": stat,
        "p_value": p,
        "is_normal": p > 0.05
    }


def check_stationarity(series: pd.Series):
    """
    Ø§Ø®ØªØ¨Ø§Ø± ADF Ù„Ù„Ø«Ø¨Ø§Øª.
    H0: Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØºÙŠØ± Ø«Ø§Ø¨ØªØ© (ÙŠÙˆØ¬Ø¯ Ø¬Ø°Ø± ÙˆØ§Ø­Ø¯).
    """
    s = series.dropna()
    try:
        result = adfuller(s)
        adf_stat, p, used_lag, nobs, crit_vals, icbest = result
        is_stationary = p < 0.05
    except Exception:
        # ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø§Ù„Ù€ ADF Ù„Ø£ÙŠ Ø³Ø¨Ø¨
        adf_stat, p, is_stationary = np.nan, np.nan, False

    return {
        "ADF Statistic": adf_stat,
        "p_value": p,
        "is_stationary": is_stationary
    }


def apply_log_transform(series: pd.Series):
    """
    ØªØ­ÙˆÙŠÙ„ Log (Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙˆØ¬Ø¨Ø©).
    """
    return np.log(series)


def apply_differencing(series: pd.Series, order: int = 1):
    """
    Differencing Ù…Ù† Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹.
    """
    return series.diff(order)


def build_dataset(df: pd.DataFrame, feature_cols, horizon: int):
    """
    ØªØ¬Ù‡ÙŠØ² Ø¯Ø§ØªØ§ Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙ†Ø¨Ø£ Close Ø¨Ø¹Ø¯ Ø¹Ø¯Ø¯ Ø£ÙŠØ§Ù… (horizon).
    """
    df2 = df.copy()
    target_col = f"target_{horizon}"

    # Ø§Ù„Ù‡Ø¯Ù: Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø¨Ø¹Ø¯ horizon ÙŠÙˆÙ…
    df2[target_col] = df2["Close"].shift(-horizon)

    df2 = df2.dropna(subset=feature_cols + [target_col])

    if len(df2) < 100:
        return None

    X = df2[feature_cols]
    y = df2[target_col]

    n = len(df2)
    train_end = int(n * 0.8)
    val_end = int(n * 0.9)

    return {
        "X_train": X.iloc[:train_end],
        "y_train": y.iloc[:train_end],
        "X_val": X.iloc[train_end:val_end],
        "y_val": y.iloc[train_end:val_end],
        "X_test": X.iloc[val_end:],
        "y_test": y.iloc[val_end:],
    }


def train_models_for_horizon(dataset, feature_cols):
    """
    ØªØ¯Ø±ÙŠØ¨ 3 Ù†Ù…Ø§Ø°Ø¬ Ù„ÙƒÙ„ Ø£ÙÙ‚ Ø²Ù…Ù†ÙŠ.
    """
    models_def = {
        "Linear Regression": LinearRegression(),
        "Random Forest": RandomForestRegressor(
            n_estimators=300, random_state=42, n_jobs=-1
        ),
        "Gradient Boosting": GradientBoostingRegressor(random_state=42),
    }

    metrics_list = []
    trained = {}

    X_train = dataset["X_train"]
    y_train = dataset["y_train"]
    X_test = dataset["X_test"]
    y_test = dataset["y_test"]

    for name, base_model in models_def.items():
        pipe = Pipeline([
            ("scaler", StandardScaler()),
            ("model", base_model),
        ])

        pipe.fit(X_train, y_train)
        y_pred = pipe.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        # Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³Ø¹Ø± (Ø·Ù„ÙˆØ¹ / Ù†Ø²ÙˆÙ„)
        close_test = X_test["Close"].values
        dir_real = np.sign(y_test.values - close_test)
        dir_pred = np.sign(y_pred - close_test)
        directional_acc = float((dir_real == dir_pred).mean() * 100)

        metrics_list.append({
            "Model": name,
            "RMSE": rmse,
            "MAE": mae,
            "R2": r2,
            "Directional_Accuracy": directional_acc,
        })

        trained[name] = {"pipeline": pipe, "rmse": rmse}

    metrics_df = pd.DataFrame(metrics_list).sort_values(
        "Directional_Accuracy", ascending=False
    )
    return trained, metrics_df

# ============================
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª â€“ Sidebar
# ============================

with st.sidebar:
    st.title("âš™ï¸ Configuration")

    market = st.selectbox(
        "Select Market",
        ["Saudi Stocks (Tadawul - TASI)", "US Stocks", "Crypto"],
        index=0,
    )

    default_ticker = "2010.SR" if market == "Saudi Stocks (Tadawul - TASI)" else "AAPL"
    ticker = st.text_input("Enter Stock Ticker", default_ticker)

    years_hist = st.slider("Years of Historical Data", 1, 10, 5)

    horizons_labels = ["7 Days", "14 Days", "30 Days"]
    horizons_selected_labels = st.multiselect(
        "Forecast Horizons", horizons_labels, default=horizons_labels
    )
    horizon_map = {"7 Days": 7, "14 Days": 14, "30 Days": 30}
    horizons = [horizon_map[h] for h in horizons_selected_labels]

    train_button = st.button("ðŸš€ Train Models & Forecast")

    st.markdown("---")
    st.subheader("Notes")
    st.markdown(
        """
        â€¢ ÙŠØªÙ… ÙØ­Øµ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ Ù„Ù„Ø³Ù„Ø³Ù„Ø© (Shapiro).  
        â€¢ Ø¥Ø°Ø§ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ© â†’ ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚ Log.  
        â€¢ ÙŠØªÙ… ÙØ­Øµ Ø§Ù„Ø«Ø¨Ø§Øª (ADF Test).  
        â€¢ Ø¥Ø°Ø§ ØºÙŠØ± Ø«Ø§Ø¨ØªØ© â†’ ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚ Differencing.  
        â€¢ ÙƒÙ„ Ø°Ù„Ùƒ Ù‚Ø¨Ù„ Ø¨Ù†Ø§Ø¡ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬.
        """
    )

# ============================
# Tabs
# ============================

st.title("ðŸ“ˆ Advanced Stock Price Forecaster")

tab_summary, tab_forecasts, tab_models = st.tabs(
    ["Pipeline Summary", "Future Price Forecasts", "Model Performance"]
)

if not train_button:
    with tab_summary:
        st.info("â¬…ï¸ Ø§Ø®ØªØ± Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ø«Ù… Ø§Ø¶ØºØ· **Train Models & Forecast**.")
    with tab_forecasts:
        st.warning("Ù„Ù… ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø¹Ø¯.")
    with tab_models:
        st.warning("Ù„Ù… ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø¹Ø¯.")
else:
    # ============================
    # 1) Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    # ============================
    current_price, df_raw = load_stock_data(ticker, years_hist)

    if df_raw.empty:
        st.error("Ù„Ù… ÙŠØªÙ… Ø¬Ù„Ø¨ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Yahoo Finance. ØªØ­Ù‚Ù‚ÙŠ Ù…Ù† Ø§Ù„Ø±Ù…Ø² Ø£Ùˆ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ù†ÙˆØ§Øª.")
    else:
        # ============================
        # 2) Ù…Ø¤Ø´Ø±Ø§Øª ÙÙ†ÙŠØ© + Lags
        # ============================
        df_feat = add_technical_indicators(df_raw)
        df_feat = add_lag_features(df_feat)

        # ============================
        # 3) Normality + Log Transform
        # ============================
        normal_res = check_normality(df_feat["Close"])
        use_log = not normal_res["is_normal"]

        if use_log:
            df_feat["Close_log"] = apply_log_transform(df_feat["Close"])
            series_for_adf = df_feat["Close_log"]
        else:
            df_feat["Close_log"] = apply_log_transform(df_feat["Close"])
            series_for_adf = df_feat["Close"]

        # ============================
        # 4) ADF + Differencing
        # ============================
        adf_res = check_stationarity(series_for_adf)
        use_diff = not adf_res["is_stationary"]

        if use_diff:
            df_feat["Close_diff1"] = apply_differencing(series_for_adf)
        else:
            # Ø­ØªÙ‰ Ù„Ùˆ Ø«Ø§Ø¨ØªØ© Ù†Ø¶ÙŠÙ diff ÙƒÙ…ÙŠØ²Ø© (ØªØ¹Ø¨Ù‘Ø± Ø¹Ù† Ø§Ù„ØªØºÙŠØ±)
            df_feat["Close_diff1"] = apply_differencing(series_for_adf)

        # Ø£Ø³Ù‚Ø· Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù†Ø§Ù‚ØµØ© Ø¨Ø³Ø¨Ø¨ rolling/diff/log
        df_feat = df_feat.dropna()

        # ============================
        # 5) ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù„Ù†Ù…Ø§Ø°Ø¬
        # ============================
        feature_cols = [
            # Ø§Ù„Ø³Ø¹Ø± ÙˆØ§Ù„Ø­Ø¬Ù…
            "Close", "Volume",
            # Ù…Ø¤Ø´Ø±Ø§Øª ÙÙ†ÙŠØ©
            "SMA_20", "SMA_50",
            "EMA_10", "EMA_20",
            "RSI", "MACD", "Signal",
            # Log + Diff
            "Close_log", "Close_diff1",
            # Lags
            "Close_lag_1", "Close_lag_2", "Close_lag_3",
            "Close_lag_5", "Close_lag_7", "Close_lag_10", "Close_lag_14",
            # Returns
            "Return_1", "Return_3", "Return_7",
            # Volatility
            "Volatility_7", "Volatility_14",
        ]

        # ØªØ£ÙƒØ¯ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©
        feature_cols = [c for c in feature_cols if c in df_feat.columns]

        results_by_h = {}
        models_by_h = {}
        forecasts = {}

        # ============================
        # 6) ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„ÙƒÙ„ Ø£ÙÙ‚
        # ============================
        for h in horizons:
            dataset = build_dataset(df_feat, feature_cols, horizon=h)
            if dataset is None:
                continue

            trained, df_metrics = train_models_for_horizon(dataset, feature_cols)
            results_by_h[h] = df_metrics
            models_by_h[h] = trained

            # ØªÙˆÙ‚Ø¹Ø§Øª Ù„ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø£ÙØ¶Ù„ 3
            forecasts[h] = {}
            for model_name in df_metrics["Model"].head(3):
                pipe = trained[model_name]["pipeline"]
                rmse = trained[model_name]["rmse"]

                X_last = df_feat[feature_cols].iloc[[-1]]
                pred = float(pipe.predict(X_last)[0])

                diff_pct = (pred - current_price) / current_price * 100 if current_price else np.nan
                low = pred - rmse
                high = pred + rmse

                if diff_pct > 1:
                    sentiment = "Bullish"
                elif diff_pct < -1:
                    sentiment = "Bearish"
                else:
                    sentiment = "Neutral"

                forecasts[h][model_name] = {
                    "forecast": pred,
                    "diff_pct": diff_pct,
                    "low": low,
                    "high": high,
                    "sentiment": sentiment
                }

        if not results_by_h:
            with tab_summary:
                st.error("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø¢ÙØ§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
        else:
            # Ù†Ø®ØªØ§Ø± Ø£ÙÙ‚ Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø¹Ø±Ø¶ (ÙŠÙØ¶Ù„ 7)
            primary_h = 7 if 7 in results_by_h else sorted(results_by_h.keys())[0]
            primary_df = results_by_h[primary_h]

            # ============================
            # TAB 1 â€“ Pipeline Summary
            # ============================
            with tab_summary:
                st.subheader("1ï¸âƒ£ Data Collection")
                st.success(
                    f"Loaded {len(df_raw)} rows for **{ticker}** "
                    f"in market **{market}**. Current Price: **{current_price:.2f}**"
                )

                st.subheader("2ï¸âƒ£ Normality Check (Shapiro-Wilk)")
                st.write(f"Statistic: `{normal_res['statistic']:.4f}`, p-value: `{normal_res['p_value']:.4f}`")
                if normal_res["is_normal"]:
                    st.success("âœ”ï¸ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ (Ù„Ù… ÙŠØªÙ… ÙØ±Ø¶ Log ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬).")
                else:
                    st.warning("âŒ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù„Ø§ ØªØªØ¨Ø¹ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ. ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ± Log (Close_log) ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙƒÙ…ÙŠØ²Ø©.")

                st.subheader("3ï¸âƒ£ Stationarity Check (ADF Test)")
                st.write(f"ADF Statistic: `{adf_res['ADF Statistic']:.4f}`, p-value: `{adf_res['p_value']:.4f}`")
                if adf_res["is_stationary"]:
                    st.success("âœ”ï¸ Ø§Ù„Ø³Ù„Ø³Ù„Ø© (Ø£Ùˆ Log) Ø«Ø§Ø¨ØªØ© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹ ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹.")
                else:
                    st.warning("âŒ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØºÙŠØ± Ø«Ø§Ø¨ØªØ©. ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ± Diff (Close_diff1) ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙƒÙ…ÙŠØ²Ø©.")

                st.subheader("4ï¸âƒ£ Feature Engineering")
                st.info(
                    "ØªÙ… Ø¥Ø¶Ø§ÙØ©: SMA/EMA/RSI/MACD + Log + Diff + Lags + Returns + Volatility "
                    "Ø«Ù… Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù†Ø§Ù‚ØµØ© Ù…Ù† rolling/diff."
                )
                st.write(f"Final feature rows used for modeling: `{len(df_feat)}`")

                st.subheader("5ï¸âƒ£ Model Training & Evaluation")
                all_metrics = []
                for h, metrics in results_by_h.items():
                    df_m = metrics.copy()
                    df_m.insert(0, "Horizon", f"{h} days")
                    all_metrics.append(df_m)

                all_metrics_df = pd.concat(all_metrics, ignore_index=True)
                st.dataframe(all_metrics_df, use_container_width=True)

            # ============================
            # TAB 2 â€“ Forecasts
            # ============================
            with tab_forecasts:
                st.subheader("Future Price Forecasts (Top 3 Models)")
                st.markdown(f"**Current Price:** {current_price:.2f}")

                for h in horizons:
                    if h not in forecasts:
                        continue

                    st.markdown(f"## ðŸ•’ {h} Days Forecast")

                    for model_name, info in forecasts[h].items():
                        col1, col2, col3 = st.columns([2, 2, 2])

                        with col1:
                            st.markdown(f"**{model_name}**")
                            st.metric(
                                "Forecast",
                                f"{info['forecast']:.2f}",
                                f"{info['diff_pct']:.2f}%"
                            )

                        with col2:
                            st.write(f"Range: {info['low']:.2f} â€“ {info['high']:.2f}")

                        with col3:
                            if info["sentiment"] == "Bullish":
                                st.success("Bullish")
                            elif info["sentiment"] == "Bearish":
                                st.error("Bearish")
                            else:
                                st.info("Neutral")

                    st.markdown("---")

            # ============================
            # TAB 3 â€“ Model Performance
            # ============================
            with tab_models:
                st.subheader(f"Top Models â€“ {primary_h} Days")
                st.dataframe(primary_df, use_container_width=True)

                st.markdown("### Directional Accuracy")
                st.bar_chart(primary_df.set_index("Model")[["Directional_Accuracy"]])

                st.markdown("### RMSE")
                st.bar_chart(primary_df.set_index("Model")[["RMSE"]])

                # Ø¹Ø±Ø¶ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ¹Ù„ÙŠØ© Ù„Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
                best_model_name = primary_df.iloc[0]["Model"]
                ds_primary = build_dataset(df_feat, feature_cols, primary_h)
                if ds_primary is not None:
                    X_test = ds_primary["X_test"]
                    y_test = ds_primary["y_test"]
                    pipe_best = models_by_h[primary_h][best_model_name]["pipeline"]
                    preds = pipe_best.predict(X_test)

                    comp_df = pd.DataFrame(
                        {
                            "Actual": y_test,
                            "Predicted": preds,
                        },
                        index=X_test.index,
                    )
                    st.markdown(f"### Predictions vs Actual â€“ {best_model_name} ({primary_h} days)")
                    st.line_chart(comp_df)
