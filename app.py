# app.py
# Advanced Stock Price Forecaster
# Yahoo Finance + Feature Engineering + Log-Return Targets + Heuristic Normality & Stationarity + Plots

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ============================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
# ============================
st.set_page_config(
    page_title="Advanced Stock Price Forecaster",
    layout="wide"
)

# ============================
# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
# ============================

def load_stock_data(ticker: str, years: int):
    """ÙŠØ¬Ù„Ø¨ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ + Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Yahoo Finance."""
    stock = yf.Ticker(ticker)

    # Ø³Ø¹Ø± Ù„Ø­Ø¸ÙŠ
    info = getattr(stock, "fast_info", {}) or {}
    current_price = info.get("last_price", None)
    if current_price is None:
        hist = stock.history(period="1d")
        if not hist.empty:
            current_price = float(hist["Close"].iloc[-1])
        else:
            current_price = np.nan

    # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø³Ù†ÙˆØ§Øª
    df = stock.history(period=f"{years}y")
    df = df.dropna()

    return current_price, df


def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """Ù…Ø¤Ø´Ø±Ø§Øª ÙÙ†ÙŠØ©: SMA, EMA, RSI, MACD."""
    df = df.copy()

    df["SMA_20"] = df["Close"].rolling(20).mean()
    df["SMA_50"] = df["Close"].rolling(50).mean()
    df["EMA_10"] = df["Close"].ewm(span=10, adjust=False).mean()
    df["EMA_20"] = df["Close"].ewm(span=20, adjust=False).mean()

    # RSI ØªÙ‚Ø±ÙŠØ¨ÙŠ
    delta = df["Close"].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(14).mean()
    avg_loss = loss.rolling(14).mean()
    rs = avg_gain / (avg_loss + 1e-9)
    df["RSI"] = 100 - (100 / (1 + rs))

    # MACD
    ema12 = df["Close"].ewm(span=12, adjust=False).mean()
    ema26 = df["Close"].ewm(span=26, adjust=False).mean()
    df["MACD"] = ema12 - ema26
    df["Signal"] = df["MACD"].ewm(span=9, adjust=False).mean()

    return df


def add_lag_features(df: pd.DataFrame) -> pd.DataFrame:
    """Ø¥Ø¶Ø§ÙØ© Lags + Returns + Volatility."""
    df = df.copy()

    # Lags Ù„Ù„Ø£Ø³Ø¹Ø§Ø±
    for lag in [1, 2, 3, 5, 7, 10, 14]:
        df[f"Close_lag_{lag}"] = df["Close"].shift(lag)

    # Returns
    df["Return_1"] = df["Close"].pct_change(1)
    df["Return_3"] = df["Close"].pct_change(3)
    df["Return_7"] = df["Close"].pct_change(7)

    # Volatility
    df["Volatility_7"] = df["Return_1"].rolling(7).std()
    df["Volatility_14"] = df["Return_1"].rolling(14).std()

    return df


def check_normality_heuristic(series: pd.Series):
    """ÙØ­Øµ ØªÙ‚Ø±ÙŠØ¨ Ù„Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… skew & kurtosis."""
    s = series.dropna()
    if len(s) == 0:
        return {"skew": np.nan, "kurtosis": np.nan, "is_normal_like": False}

    skew = float(s.skew())
    kurt = float(s.kurtosis())
    is_normal_like = (abs(skew) < 0.5) and (abs(kurt) < 1.0)

    return {
        "skew": skew,
        "kurtosis": kurt,
        "is_normal_like": is_normal_like,
    }


def check_stationarity_heuristic(series: pd.Series):
    """
    ÙØ­Øµ ØªÙ‚Ø±ÙŠØ¨ÙŠ Ù„Ù„Ø«Ø¨Ø§Øª Ø¨Ø¯ÙˆÙ† ADF:
    - Autocorrelation lag1
    - ØªØºÙŠÙ‘Ø± Ø§Ù„Ù…ØªÙˆØ³Ø· ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ† Ø¨ÙŠÙ† 3 Ù…Ù‚Ø§Ø·Ø¹.
    """
    s = series.dropna()
    if len(s) < 40:
        return {
            "autocorr_lag1": np.nan,
            "mean_range": np.nan,
            "var_range": np.nan,
            "is_stationary_like": False,
        }

    ac1 = float(s.autocorr(lag=1))

    n = len(s)
    third = n // 3
    s1 = s.iloc[:third]
    s2 = s.iloc[third:2 * third]
    s3 = s.iloc[2 * third:]

    m1, m2, m3 = s1.mean(), s2.mean(), s3.mean()
    v1, v2, v3 = s1.var(), s2.var(), s3.var()

    mean_range = float(max(m1, m2, m3) - min(m1, m2, m3))
    var_range = float(max(v1, v2, v3) - min(v1, v2, v3))

    mean_scale = abs(s.mean()) + 1e-6
    var_scale = s.var() + 1e-6

    mean_rel = mean_range / mean_scale
    var_rel = var_range / var_scale

    # ØªÙ‚Ø±ÙŠØ¨: Ù„Ùˆ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ù‹Ø§ ÙˆÙ…Ø¹Ø§Ù‡ ØªØºÙŠÙ‘Ø± ÙƒØ¨ÙŠØ± ÙÙŠ Ø§Ù„Ù…ØªÙˆØ³Ø·/Ø§Ù„ØªØ¨Ø§ÙŠÙ† â†’ ØºÙŠØ± Ø«Ø§Ø¨ØªØ©
    is_stationary_like = not ((ac1 > 0.9) and (mean_rel > 0.3 or var_rel > 0.5))

    return {
        "autocorr_lag1": ac1,
        "mean_range": mean_range,
        "var_range": var_range,
        "is_stationary_like": is_stationary_like,
    }


def apply_log_transform(series: pd.Series):
    """ØªØ­ÙˆÙŠÙ„ Log."""
    return np.log(series)


def apply_differencing(series: pd.Series, order: int = 1):
    """Differencing Ù…Ù† Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹."""
    return series.diff(order)


def build_dataset(df: pd.DataFrame, feature_cols, horizon: int):
    """
    ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªÙˆÙ‚Ø¹ log-return Ø®Ù„Ø§Ù„ horizon ÙŠÙˆÙ… Ø¨Ø¯Ù„ Ø§Ù„Ø³Ø¹Ø± Ù†ÙØ³Ù‡.
    """
    df2 = df.copy()

    # log price
    df2["log_close_base"] = np.log(df2["Close"])

    target_col = f"target_{horizon}"
    # log-return Ø¨Ø¹Ø¯ horizon ÙŠÙˆÙ…
    df2[target_col] = df2["log_close_base"].shift(-horizon) - df2["log_close_base"]

    df2 = df2.dropna(subset=feature_cols + [target_col])

    if len(df2) < 100:
        return None

    X = df2[feature_cols]
    y = df2[target_col]          # log-return

    n = len(df2)
    train_end = int(n * 0.8)
    val_end = int(n * 0.9)

    return {
        "X_train": X.iloc[:train_end],
        "y_train": y.iloc[:train_end],
        "X_val": X.iloc[train_end:val_end],
        "y_val": y.iloc[train_end:val_end],
        "X_test": X.iloc[val_end:],
        "y_test": y.iloc[val_end:],
        "base_close_test": X.iloc[val_end:]["Close"],  # Ù„Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ Ù„Ø§Ø­Ù‚Ø§Ù‹
    }


def train_models_for_horizon(dataset, feature_cols):
    """
    ØªØ¯Ø±ÙŠØ¨ 3 Ù†Ù…Ø§Ø°Ø¬ Ù„ÙƒÙ„ Ø£ÙÙ‚ Ø²Ù…Ù†ÙŠ Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… log-return ÙƒÙ‡Ø¯ÙØŒ
    Ø«Ù… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± (Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­ÙˆÙŠÙ„).
    """
    models_def = {
        "Linear Regression": LinearRegression(),
        "Random Forest": RandomForestRegressor(
            n_estimators=200,
            max_depth=3,
            min_samples_leaf=10,
            random_state=42,
            n_jobs=-1
        ),
        "Gradient Boosting": GradientBoostingRegressor(
            n_estimators=200,
            learning_rate=0.05,
            max_depth=3,
            random_state=42
        ),
    }

    metrics_list = []
    trained = {}

    X_train = dataset["X_train"]
    y_train = dataset["y_train"]              # log-return
    X_test = dataset["X_test"]
    y_test = dataset["y_test"]                # log-return
    base_close_test = dataset["base_close_test"].values  # Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠØ©

    for name, base_model in models_def.items():
        pipe = Pipeline([
            ("scaler", StandardScaler()),
            ("model", base_model),
        ])

        pipe.fit(X_train, y_train)
        y_pred = pipe.predict(X_test)         # log-return Ù…ØªÙ†Ø¨Ø£

        # Ù†Ø­ÙˆÙ„ log-return Ø¥Ù„Ù‰ Ø£Ø³Ø¹Ø§Ø±
        y_test_price = base_close_test * np.exp(y_test.values)
        y_pred_price = base_close_test * np.exp(y_pred)

        mse = mean_squared_error(y_test_price, y_pred_price)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test_price, y_pred_price)
        r2 = r2_score(y_test_price, y_pred_price)

        dir_real = np.sign(y_test_price - base_close_test)
        dir_pred = np.sign(y_pred_price - base_close_test)
        directional_acc = float((dir_real == dir_pred).mean() * 100)

        metrics_list.append({
            "Model": name,
            "RMSE": rmse,
            "MAE": mae,
            "R2": r2,
            "Directional_Accuracy": directional_acc,
        })

        trained[name] = {"pipeline": pipe, "rmse": rmse}

    metrics_df = pd.DataFrame(metrics_list).sort_values(
        "Directional_Accuracy", ascending=False
    )
    return trained, metrics_df

# ============================
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª â€“ Sidebar
# ============================

with st.sidebar:
    st.title("âš™ï¸ Configuration")

    market = st.selectbox(
        "Select Market",
        ["Saudi Stocks (Tadawul - TASI)", "US Stocks", "Crypto"],
        index=0,
    )

    default_ticker = "2010.SR" if market == "Saudi Stocks (Tadawul - TASI)" else "AAPL"
    ticker = st.text_input("Enter Stock Ticker", default_ticker)

    years_hist = st.slider("Years of Historical Data", 1, 10, 5)

    horizons_labels = ["7 Days", "14 Days", "30 Days"]
    horizons_selected_labels = st.multiselect(
        "Forecast Horizons", horizons_labels, default=horizons_labels
    )
    horizon_map = {"7 Days": 7, "14 Days": 14, "30 Days": 30}
    horizons = [horizon_map[h] for h in horizons_selected_labels]

    train_button = st.button("ğŸš€ Train Models & Forecast")

    st.markdown("---")
    st.subheader("Analysis Steps")
    st.markdown(
        """
        â€¢ Normality: ØªÙ‚Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **skew & kurtosis**.  
        â€¢ Stationarity: ØªÙ‚Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **autocorrelation + ØªØºÙŠØ± Ø§Ù„Ù…ØªÙˆØ³Ø· / Ø§Ù„ØªØ¨Ø§ÙŠÙ†**.  
        â€¢ Ù‡Ø¯Ù Ø§Ù„ØªÙ†Ø¨Ø¤ = **log-return** Ù„ÙƒÙ„ Ø£ÙÙ‚ Ø²Ù…Ù†ÙŠ.  
        â€¢ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØªÙØ­ÙˆÙ‘Ù„ Ø¥Ù„Ù‰ Ø£Ø³Ø¹Ø§Ø± Ù„Ù‚ÙŠØ§Ø³ Ø§Ù„Ø®Ø·Ø£ ÙˆØ¹Ø±Ø¶ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª.
        """
    )

# ============================
# Tabs
# ============================

st.title("ğŸ“ˆ Advanced Stock Price Forecaster")

tab_summary, tab_forecasts, tab_models = st.tabs(
    ["Pipeline Summary", "Future Price Forecasts", "Model Performance"]
)

if not train_button:
    with tab_summary:
        st.info("â¬…ï¸ Ø§Ø®ØªØ± Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ø«Ù… Ø§Ø¶ØºØ· **Train Models & Forecast**.")
    with tab_forecasts:
        st.warning("Ù„Ù… ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø¹Ø¯.")
    with tab_models:
        st.warning("Ù„Ù… ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø¹Ø¯.")
else:
    current_price, df_raw = load_stock_data(ticker, years_hist)

    if df_raw.empty:
        with tab_summary:
            st.error("Ù„Ù… ÙŠØªÙ… Ø¬Ù„Ø¨ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Yahoo Finance. ØªØ­Ù‚Ù‚ÙŠ Ù…Ù† Ø±Ù…Ø² Ø§Ù„Ø³Ù‡Ù… Ø£Ùˆ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ù†ÙˆØ§Øª.")
    else:
        # 1) Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª
        df_feat = add_technical_indicators(df_raw)
        df_feat = add_lag_features(df_feat)

        # 2) Normality heuristic
        normal_res = check_normality_heuristic(df_feat["Close"])
        use_log = not normal_res["is_normal_like"]
        df_feat["Close_log"] = apply_log_transform(df_feat["Close"])

        # 3) Stationarity heuristic
        series_for_stationarity = df_feat["Close_log"] if use_log else df_feat["Close"]
        stat_res = check_stationarity_heuristic(series_for_stationarity)

        # diff ÙƒØ³ÙÙ…Ø©
        df_feat["Close_diff1"] = apply_differencing(series_for_stationarity)

        # Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ©
        df_feat = df_feat.dropna()

        # 4) Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª
        feature_cols = [
            "Close", "Volume",
            "SMA_20", "SMA_50",
            "EMA_10", "EMA_20",
            "RSI", "MACD", "Signal",
            "Close_log", "Close_diff1",
            "Close_lag_1", "Close_lag_2", "Close_lag_3",
            "Close_lag_5", "Close_lag_7", "Close_lag_10", "Close_lag_14",
            "Return_1", "Return_3", "Return_7",
            "Volatility_7", "Volatility_14",
        ]
        feature_cols = [c for c in feature_cols if c in df_feat.columns]

        results_by_h = {}
        models_by_h = {}
        forecasts = {}

        # 5) ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        for h in horizons:
            dataset = build_dataset(df_feat, feature_cols, horizon=h)
            if dataset is None:
                continue

            trained, df_metrics = train_models_for_horizon(dataset, feature_cols)
            results_by_h[h] = df_metrics
            models_by_h[h] = trained

            forecasts[h] = {}
            for model_name in df_metrics["Model"].head(3):
                pipe = trained[model_name]["pipeline"]
                rmse = trained[model_name]["rmse"]

                X_last = df_feat[feature_cols].iloc[[-1]]
                base_last = X_last["Close"].values[0]

                # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ…ÙŠ Ø«Ù… ØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ø³Ø¹Ø±
                pred_return = float(pipe.predict(X_last)[0])
                pred = base_last * np.exp(pred_return)

                diff_pct = (pred - current_price) / current_price * 100 if current_price else np.nan
                low = pred - rmse
                high = pred + rmse

                if diff_pct > 1:
                    sentiment = "Bullish"
                elif diff_pct < -1:
                    sentiment = "Bearish"
                else:
                    sentiment = "Neutral"

                forecasts[h][model_name] = {
                    "forecast": pred,
                    "diff_pct": diff_pct,
                    "low": low,
                    "high": high,
                    "sentiment": sentiment
                }

        if not results_by_h:
            with tab_summary:
                st.error("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø¢ÙØ§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
        else:
            primary_h = 7 if 7 in results_by_h else sorted(results_by_h.keys())[0]
            primary_df = results_by_h[primary_h]

            # ============================
            # TAB 1 â€“ Pipeline Summary
            # ============================
            with tab_summary:
                st.subheader("1ï¸âƒ£ Data Collection")
                st.success(
                    f"Loaded {len(df_raw)} rows for **{ticker}** "
                    f"in market **{market}**. Current Price: **{current_price:.2f}**"
                )

                st.subheader("2ï¸âƒ£ Normality Check (Heuristic)")
                st.write(f"Skew: `{normal_res['skew']:.4f}`, Kurtosis: `{normal_res['kurtosis']:.4f}`")
                if normal_res["is_normal_like"]:
                    st.success("âœ”ï¸ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØªØ¨Ø¯Ùˆ Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ (Log Ù…Ø¬Ø±Ø¯ Ø³ÙÙ…Ø© Ø¥Ø¶Ø§ÙÙŠØ©).")
                else:
                    st.warning("âŒ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø¨Ø¹ÙŠØ¯Ø© Ø¹Ù† Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ. ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Close_log ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙƒØ³ÙÙ…Ø© ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")

                st.subheader("3ï¸âƒ£ Stationarity Check (Heuristic)")
                st.write(f"Autocorr (lag 1): `{stat_res['autocorr_lag1']:.4f}`")
                st.write(f"Mean range (3 segments): `{stat_res['mean_range']:.4f}`")
                st.write(f"Var range (3 segments): `{stat_res['var_range']:.4f}`")
                if stat_res["is_stationary_like"]:
                    st.success("âœ”ï¸ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØªØ¨Ø¯Ùˆ Ø´Ø¨Ù‡ Ø«Ø§Ø¨ØªØ© (Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… diff ÙƒÙ…ÙŠØ²Ø© Ù„Ù„ØªØºÙŠØ±).")
                else:
                    st.warning("âŒ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ÙÙŠÙ‡Ø§ Ø§ØªØ¬Ø§Ù‡ Ù‚ÙˆÙŠ / Ø¹Ø¯Ù… Ø«Ø¨Ø§Øª. ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… diff ÙƒÙ…ÙŠØ²Ø© Ù…Ù‡Ù…Ø© Ù„Ù„Ù†Ù…Ø§Ø°Ø¬.")

                st.subheader("4ï¸âƒ£ Feature Engineering")
                st.info(
                    "ØªÙ… Ø¥Ø¶Ø§ÙØ© SMA/EMA/RSI/MACD + Log + Diff + Lags + Returns + Volatility "
                    "Ù…Ø¹ Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ØªØ£Ø«Ø±Ø© Ø¨Ù€ rolling/diff."
                )
                st.write(f"Final feature rows: `{len(df_feat)}`")

                # 5ï¸âƒ£ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
                st.subheader("5ï¸âƒ£ Data Distribution Before & After Processing")

                col_a, col_b = st.columns(2)

                with col_a:
                    st.markdown("**Raw Close Price Distribution**")
                    fig1, ax1 = plt.subplots(figsize=(4, 3))
                    ax1.hist(df_raw["Close"].dropna(), bins=30, alpha=0.8)
                    ax1.set_xlabel("Close")
                    ax1.set_ylabel("Frequency")
                    ax1.set_title("Raw Close")
                    st.pyplot(fig1)

                with col_b:
                    if use_log:
                        st.markdown("**Processed (Log Close) Distribution**")
                        processed_series = df_feat["Close_log"]
                    else:
                        st.markdown("**Processed (Diff) Distribution**")
                        processed_series = df_feat["Close_diff1"]

                    fig2, ax2 = plt.subplots(figsize=(4, 3))
                    ax2.hist(processed_series.dropna(), bins=30, alpha=0.8)
                    ax2.set_xlabel("Value")
                    ax2.set_ylabel("Frequency")
                    ax2.set_title("Processed Series")
                    st.pyplot(fig2)

                st.subheader("6ï¸âƒ£ Model Training & Evaluation")
                all_metrics = []
                for h, metrics in results_by_h.items():
                    df_m = metrics.copy()
                    df_m.insert(0, "Horizon", f"{h} days")
                    all_metrics.append(df_m)
                all_metrics_df = pd.concat(all_metrics, ignore_index=True)
                st.dataframe(all_metrics_df, use_container_width=True)

            # ============================
            # TAB 2 â€“ Forecasts
            # ============================
            with tab_forecasts:
                st.subheader("Future Price Forecasts (Top 3 Models)")
                st.markdown(f"**Current Price:** {current_price:.2f}")

                # Ø¨Ø·Ø§Ù‚Ø§Øª Ø§Ù„ØªÙˆÙ‚Ø¹ Ù„ÙƒÙ„ Ø£ÙÙ‚
                for h in horizons:
                    if h not in forecasts:
                        continue

                    st.markdown(f"## ğŸ•’ {h} Days Forecast")
                    for model_name, info in forecasts[h].items():
                        col1, col2, col3 = st.columns([2, 2, 2])

                        with col1:
                            st.markdown(f"**{model_name}**")
                            st.metric(
                                "Forecast",
                                f"{info['forecast']:.2f}",
                                f"{info['diff_pct']:.2f}%",
                            )

                        with col2:
                            st.write(f"Range: {info['low']:.2f} â€“ {info['high']:.2f}")

                        with col3:
                            if info["sentiment"] == "Bullish":
                                st.success("Bullish")
                            elif info["sentiment"] == "Bearish":
                                st.error("Bearish")
                            else:
                                st.info("Neutral")

                    st.markdown("---")

                # Ø±Ø³Ù… Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© + Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙ†Ø¨Ø¤ (Ensemble)
                st.subheader("ğŸ“ˆ Forecast Plot (History + Ensemble Points)")

                hist_series = df_raw["Close"].copy().tail(120)
                if len(hist_series) > 0:
                    last_date = hist_series.index[-1]

                    future_points = {}
                    for h in horizons:
                        if h not in forecasts or len(forecasts[h]) == 0:
                            continue
                        values = [info["forecast"] for info in forecasts[h].values()]
                        ens_pred = float(np.mean(values))
                        future_date = last_date + pd.Timedelta(days=h)
                        future_points[future_date] = ens_pred

                    if future_points:
                        future_series = pd.Series(future_points, name="Forecast")
                        df_plot = pd.DataFrame(index=hist_series.index.union(future_series.index))
                        df_plot["Close"] = hist_series
                        df_plot["Forecast"] = future_series
                        st.line_chart(df_plot)
                    else:
                        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù‚Ø§Ø· Forecast ÙƒØ§ÙÙŠØ© Ù„Ø±Ø³Ù…Ù‡Ø§.")
                else:
                    st.info("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù‚Ù„ÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ø±Ø³Ù… Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©.")

            # ============================
            # TAB 3 â€“ Model Performance
            # ============================
            with tab_models:
                st.subheader(f"Top Models â€“ {primary_h} Days")
                st.dataframe(primary_df, use_container_width=True)

                st.markdown("### Directional Accuracy")
                st.bar_chart(primary_df.set_index("Model")[["Directional_Accuracy"]])

                st.markdown("### RMSE")
                st.bar_chart(primary_df.set_index("Model")[["RMSE"]])

                best_model_name = primary_df.iloc[0]["Model"]
                ds_primary = build_dataset(df_feat, feature_cols, primary_h)
                if ds_primary is not None:
                    X_test = ds_primary["X_test"]
                    y_test = ds_primary["y_test"]
                    base_close_test = ds_primary["base_close_test"].values
                    pipe_best = models_by_h[primary_h][best_model_name]["pipeline"]
                    y_pred = pipe_best.predict(X_test)

                    y_test_price = base_close_test * np.exp(y_test.values)
                    y_pred_price = base_close_test * np.exp(y_pred)

                    comp_df = pd.DataFrame(
                        {"Actual": y_test_price, "Predicted": y_pred_price},
                        index=X_test.index,
                    )
                    st.markdown(f"### Predictions vs Actual â€“ {best_model_name} ({primary_h} days)")
                    st.line_chart(comp_df)
